{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install spacy\n",
    "%pip install nltk\n",
    "%pip install swig==3.0.6\n",
    "%pip install jamspell\n",
    "%pip install -q transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library and Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk import word_tokenize,sent_tokenize,tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from spacy.matcher import Matcher\n",
    "import jamspell\n",
    "import locale\n",
    "from transformers import pipeline\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('words')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokenizer = spacy.load(\"en_core_web_sm\")\n",
    "sentence_recognizer = spacy.load(\"en_core_web_sm\", exclude=[\"parser\"])\n",
    "sentence_recognizer.enable_pipe(\"senter\")\n",
    "corrector = jamspell.TSpellCorrector()\n",
    "corrector.LoadLangModel(\"en.bin\")\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset and read data into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = 'datasetPath'\n",
    "df = pd.read_csv(train_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering - Get Average Word Length of each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word_len(review):\n",
    "  tokens = word_tokenize(review)\n",
    "  words = [word for word in tokens if word.isalpha()]\n",
    "  tot_no_words = len(words)\n",
    "  length_of_words = 0\n",
    "  for word in words:\n",
    "    length_of_words += len(word)\n",
    "  return length_of_words/tot_no_words,tot_no_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering - Get Average Sentence Length of each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_sentence_len(review):\n",
    "  sentences = sent_tokenize(review)\n",
    "  tot_sent_number = len(sentences)\n",
    "  length_sent = 0\n",
    "  for sentence in sentences:\n",
    "    length_sent += len(sentence)\n",
    "  return length_sent/tot_sent_number , tot_sent_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering - POS Tagging for each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tagging(review):\n",
    "  tokens = word_tokenize(review)\n",
    "  tokens = [w.lower() for w in tokens]\n",
    "  table = str.maketrans('', '', string.punctuation)\n",
    "  stripped = [w.translate(table) for w in tokens]\n",
    "  words = [word for word in stripped if word.isalpha()]\n",
    "  words = [w for w in words if not w in stop_words]\n",
    "  tags = nltk.pos_tag(words, tagset = \"universal\")\n",
    "  verb_count = 0\n",
    "  adj_count = 0\n",
    "  for tag in tags:\n",
    "    if(tag[1] == 'VERB'):\n",
    "      verb_count += 1\n",
    "\n",
    "    if(tag[1] == 'ADJ'):\n",
    "      adj_count += 1\n",
    "\n",
    "  return verb_count,adj_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering - Content Diversity of each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_diversity(review):\n",
    "  tokens = word_tokenize(review)\n",
    "  tokens = [w.lower() for w in tokens]\n",
    "  table = str.maketrans('', '', string.punctuation)\n",
    "  stripped = [w.translate(table) for w in tokens]\n",
    "  words = [word for word in stripped if word.isalpha()]\n",
    "  words = [w for w in words if not w in stop_words]\n",
    "  tot_num_words = len(words)\n",
    "  tot_num_unique_words = len(set(words))\n",
    "  return tot_num_unique_words / tot_num_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering - Get Passive Voice Count of each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_NPV_count(review):\n",
    "  proc_string = tokenizer(review)\n",
    "  matcher = Matcher(tokenizer.vocab)\n",
    "  proc_sents = list(proc_string.sents)\n",
    "  passive_rule = [{'DEP':'nsubjpass'},{'DEP':'aux','OP':'*'},{'DEP':'auxpass'},{'TAG':'VBN'}]\n",
    "  matcher.add('Passive',[passive_rule])\n",
    "  matches = matcher(proc_string)\n",
    "  return len(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering - Get Number of Typos in each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_word_list = ['murg','tikki','gulab','paneer','bhartiya','pakoda', 'aloo', 'palak','naan','hyderabadi','murgh','kulche','korma','momos','kulchas','daal','malai']\n",
    "def get_NTP(paragraph):\n",
    "  tokens = word_tokenize(paragraph)\n",
    "  tokens = [w.lower() for w in tokens]\n",
    "  table = str.maketrans('', '', string.punctuation)\n",
    "  stripped = [w.translate(table) for w in tokens]\n",
    "  words = [word for word in stripped if word.isalpha()]\n",
    "  words = [w for w in words if not w in stop_words]\n",
    "  misspelled_count = 0\n",
    "  corrected_words = []\n",
    "  print(words)\n",
    "  for word in words:\n",
    "      corrected_word = corrector.FixFragment(word)\n",
    "      print(corrected_word)\n",
    "      if word not in indian_word_list and corrected_word != word:\n",
    "          misspelled_count += 1\n",
    "\n",
    "          print(\"in if:\",word)\n",
    "  return misspelled_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering - Get sentiment of each review using DistilBERT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(review):\n",
    "  sentences = sent_tokenize(review)\n",
    "  sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "  sentiment_score = 0\n",
    "  for sentence in sentences:\n",
    "    if(sentiment_pipeline(sentence)[0]['label'] ==\"POSITIVE\"):\n",
    "      sentiment_score += sentiment_pipeline(sentence)[0]['score']\n",
    "    else:\n",
    "      sentiment_score -= sentiment_pipeline(sentence)[0]['score']\n",
    "  return round(sentiment_score,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SENTIMENT_SCORE'] = [0 for i in range(0,260)]\n",
    "for ind in df.index:\n",
    "  df['SENTIMENT_SCORE'][ind] = get_sentiment(df['Review'][ind])\n",
    "  df['AWL'][ind],df['NOW'][ind] = avg_word_len(df['Review'][ind])\n",
    "  df['ASL'][ind],df['NST'][ind] = avg_sentence_len(df['Review'][ind])\n",
    "  df['NVB'][ind],df['NAJ'][ind] = pos_tagging(df['Review'][ind])\n",
    "  df['CDV'][ind] = content_diversity(df['Review'][ind])\n",
    "  df['NPV'][ind] = get_NPV_count(df['Review'][ind])\n",
    "  df['NTP'][ind] = get_NTP(df['Review'][ind])\n",
    "  df['TPR'][ind] = df['NTP'][ind] / df['NOW'][ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dataset = df.iloc[:,4:]\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "norm = scaler.fit_transform(feature_dataset)\n",
    "norm_df = pd.DataFrame(norm,columns=[feature_dataset.columns])\n",
    "target_dataset = df.iloc[:,2:3]\n",
    "dataframe = pd.concat([norm_df, target_dataset],axis=1)\n",
    "random.seed(1010)\n",
    "data = shuffle(dataframe,random_state=43)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset in 60:20:20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,:11]\n",
    "y = data.iloc[:,11:]\n",
    "\n",
    "X_train, X_rest, y_train, y_rest = train_test_split(X, y, test_size=0.20,stratify=y,random_state=55)\n",
    "X_val,X_test,y_val,y_test = train_test_split(X_rest,y_rest,test_size = 0.50,stratify = y_rest, random_state=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model - XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = XGBClassifier(\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "parameters = {\n",
    "    'max_depth': range (2, 10, 1),\n",
    "    'n_estimators': range(60, 300, 10),\n",
    "    'learning_rate': [0.1, 0.01, 0.05],\n",
    "    'subsample' : [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0],\n",
    "    'colsample_bytree' : [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0],\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=estimator,\n",
    "    param_grid=parameters,\n",
    "    scoring = 'f1',\n",
    "    n_jobs = 10,\n",
    "    cv = 10,\n",
    "    verbose=True\n",
    ")\n",
    "grid_search.fit(X, y)\n",
    "print(grid_search.best_estimator_)\n",
    "\n",
    "#Result of above hyperparameter tuning is hard-coded\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\",n_estimators=180,subsample = 0.6,random_state=42,colsample_bytree=0.7,max_depth=8,learning_rate=0.01)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_train = xgb_model.predict(X_train)\n",
    "y_pred_val = xgb_model.predict(X_val)\n",
    "y_pred_test = xgb_model.predict(X_test)\n",
    "\n",
    "mse_test = f1_score(y_test,y_pred_test)\n",
    "mse_val=f1_score(y_val, y_pred_val)\n",
    "mse_train = f1_score(y_train, y_pred_train)\n",
    "print(mse_train)\n",
    "print(mse_val)\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear',random_state = 45)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_val = model.predict(X_val)\n",
    "y_pred_test = model.predict(X_test)\n",
    "train_f1 = f1_score(y_train, y_pred_train)\n",
    "val_f1 = f1_score(y_val, y_pred_val)\n",
    "test_f1 = f1_score(y_test,y_pred_test)\n",
    "\n",
    "print(train_f1)\n",
    "print(val_f1)\n",
    "print(test_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model - Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [25, 50, 100, 150,],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'max_leaf_nodes': [3, 6, 9],\n",
    "    'criterion' : ['gini', 'entropy', 'log_loss'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(),param_grid=param_grid)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "\n",
    "#Result of above hyperparameter tuning is hard-coded\n",
    "rf_clf = RandomForestClassifier(max_depth=6, max_leaf_nodes=9, n_estimators=150, random_state=44).fit(X_train, y_train,early_stopping_rounds=50,eval_set = [(X_val,y_val)])\n",
    "y_pred_train = rf_clf.predict(X_train)\n",
    "y_pred_val = rf_clf.predict(X_val)\n",
    "y_pred_test = rf_clf.predict(X_test)\n",
    "train_f1 = f1_score(y_train, y_pred_train)\n",
    "val_f1 = f1_score(y_val, y_pred_val)\n",
    "test_f1 = f1_score(y_test,y_pred_test)\n",
    "\n",
    "print(train_f1)\n",
    "print(val_f1)\n",
    "print(test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model - Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = DecisionTreeClassifier(random_state=44)\n",
    "decisionTree.fit(X_train,y_train)\n",
    "\n",
    "y_pred_train = decisionTree.predict(X_train)\n",
    "y_pred_val = decisionTree.predict(X_val)\n",
    "y_pred_test = decisionTree.predict(X_test)\n",
    "\n",
    "train_f1 = f1_score(y_train, y_pred_train)\n",
    "val_f1 = f1_score(y_val, y_pred_val)\n",
    "test_f1 = f1_score(y_test,y_pred_test)\n",
    "\n",
    "print(train_f1)\n",
    "print(val_f1)\n",
    "print(test_f1)\n",
    "print(acc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model - Multi Layer Perceptron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters and their search space\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(8,), (4,), (2,)],\n",
    "    'activation': ['logistic', 'tanh', 'relu', 'identity'],\n",
    "    'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate' : ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "}\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(mlp, param_grid, cv=5, n_jobs=-1, verbose=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", grid_search.best_score_)\n",
    "\n",
    "best_mlp = grid_search.best_estimator_\n",
    "test_accuracy = best_mlp.score(X_rest, y_rest)\n",
    "print(\"Test Accuracy: \", test_accuracy)\n",
    "coeffs = best_mlp.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model - Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "param_grid = {'C': range(1,500),\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf','linear','sigmoid']}\n",
    "\n",
    "grid_search = GridSearchCV(svm.SVC(), param_grid, cv=5, n_jobs=-1, verbose=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#Result of above hyperparameter tuning is hard-coded\n",
    "clf = svm.SVC(C= 23, gamma= 0.1, kernel= 'linear')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "\n",
    "print(\"F1 score _test:\",f1_score(y_test, y_pred))\n",
    "print(\"F1 score _train:\",f1_score(y_train, y_pred_train))\n",
    "print(clf.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT + Feed Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "dataset = pd.concat([df[\"Review\"], df[\"Real=1/Fake=0\"]], axis=1)\n",
    "texts = list(data[\"Review\"])\n",
    "labels = list(data[\"Real=1/Fake=0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for text in texts:\n",
    "    encoded_dict = tokenizer(text, add_special_tokens=True, max_length=128, padding='max_length', truncation=True, return_tensors='pt')\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "num_batches = len(dataloader)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        print(batch)\n",
    "        optimizer.zero_grad()\n",
    "        input_ids, attention_mask, label = batch\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        loss = loss_fn(logits, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} Loss: {total_loss / len(dataloader)}\")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained('/content/gdrive/MyDrive/fine_tuned_bert_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=128)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(**encoded_data)\n",
    "\n",
    "bert_output = bert_model(input_ids)[0]\n",
    "logits = output.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 45\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "X_train, X_test, y_train, y_test = train_test_split(logits, labels, test_size=0.2, random_state=42)\n",
    "epochs = 20\n",
    "\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 2)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleClassifier(logits.size(1))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, torch.tensor(y_train))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test)\n",
    "    predicted_labels = torch.argmax(test_outputs, dim=1).tolist()\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_outputs = model(X_train)\n",
    "    predicted_labels_train = torch.argmax(train_outputs, dim=1).tolist()\n",
    "\n",
    "accuracy = accuracy_score(y_test, predicted_labels)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "trainaccuracy = accuracy_score(y_train, predicted_labels_train)\n",
    "print(f\"Accuracy: {trainaccuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 128\n",
    "num_classes = 2\n",
    "input_ids = Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_ids\")\n",
    "bert_outputs = bert_model(input_ids)[0]\n",
    "\n",
    "embedding_dim = 100\n",
    "num_classes = 2  \n",
    "model = Sequential()\n",
    "model.add(LSTM(100),input_shape=(max_seq_length, embedding_dim))\n",
    "model.add(Dense(1, activation='softmax'))  \n",
    "learning_rate = 0.0000001  \n",
    "optimizer = SGD(learning_rate=learning_rate)  \n",
    "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 128\n",
    "num_classes = 2\n",
    "input_ids = Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_ids\")\n",
    "bert_outputs = bert_model(input_ids)[0]\n",
    "\n",
    "embedding_dim = 100\n",
    "num_classes = 2\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(100),input_shape=(max_seq_length, embedding_dim)))\n",
    "model.add(Dense(1, activation='softmax')) \n",
    "learning_rate = 0.0000001 \n",
    "optimizer = SGD(learning_rate=learning_rate) \n",
    "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
